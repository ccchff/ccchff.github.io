<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Informal essay</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://ccchff.github.io/"/>
  <updated>2020-04-20T14:18:44.830Z</updated>
  <id>https://ccchff.github.io/</id>
  
  <author>
    <name>Chen Hao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python建立线性回归模型并计算相关值</title>
    <link href="https://ccchff.github.io/2020/04/15/ceshi/"/>
    <id>https://ccchff.github.io/2020/04/15/ceshi/</id>
    <published>2020-04-15T08:14:57.000Z</published>
    <updated>2020-04-20T14:18:44.830Z</updated>
    
    <content type="html"><![CDATA[<h4 id="根据所给样本数据，建立线性回归模型-Y-i-beta-0-beta-1X-i-mu-i-，其中-mu-i-sim-N-0-sigma-2"><a href="#根据所给样本数据，建立线性回归模型-Y-i-beta-0-beta-1X-i-mu-i-，其中-mu-i-sim-N-0-sigma-2" class="headerlink" title="根据所给样本数据，建立线性回归模型$Y_i=\beta_0+\beta_1X_i+\mu_i$，其中${\mu}_i \sim N(0,\sigma^2)$"></a>根据所给样本数据，建立线性回归模型$Y_i=\beta_0+\beta_1X_i+\mu_i$，其中${\mu}_i \sim N(0,\sigma^2)$</h4><p>&emsp;多元线性回归模型是指描述因变量y与一组自变量$x_1$,$x_1$,· · · ,$x_p$以及随机误差项ε的关系的等式。其一般表达式为：<br>$y=\beta_0+\beta_1x_1+\beta_2x_2+···+\beta_px_p+\varepsilon\tag{1}$<br>式中，$\beta_0$,$\beta_1$,$\beta_2$,· · ·,$\beta_p$是p+1个未知参数，$\beta_0$称为回归截距，$\beta_1$,· · ·,$\beta_p$称为回归系数，ε是随机误差项。y称为被解释变量（因变量），而$x_1$,$x_1$,· · ·,$x_p$是p个可以精确测量并可控制的自变量，称为解释变量。p=1时，式(1)即为一元线性回归模型，p≥2时，则称式(1)为多元线性回归模型。</p><p>数据导入代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">dat=pd.read_excel(<span class="string">'dat.xls'</span>)                    <span class="comment">#读取数据</span></span><br><span class="line">ones=pd.DataFrame(np.repeat(<span class="number">1</span>,dat.shape[<span class="number">0</span>]))    <span class="comment">#创建维度为dat.shape[0]的全为1的数据</span></span><br><span class="line"></span><br><span class="line">x_dat=dat.iloc[:,<span class="number">2</span>:<span class="number">7</span>]                           <span class="comment">#取源数据的第3列至第7列做为特征值</span></span><br><span class="line">X=pd.concat([ones,x_dat],axis=<span class="number">1</span>)                <span class="comment">#合并1和特征值作为输入X </span></span><br><span class="line">Y=dat.y                                         <span class="comment">#取源数据y值作为输出Y</span></span><br></pre></td></tr></table></figure><a id="more"></a><p>数据dat如下图所示：<br><img src="/2020/04/15/ceshi/dat.png" alt></p><h5 id="1-求-hat-beta-0-和-hat-beta-1-的估计值。"><a href="#1-求-hat-beta-0-和-hat-beta-1-的估计值。" class="headerlink" title="1.求$\hat{\beta_0}$和$\hat{\beta_1}$的估计值。"></a>1.求$\hat{\beta_0}$和$\hat{\beta_1}$的估计值。</h5><p>&emsp;离差平方和以及求极值方程组经整理后，可以得到用矩阵形式表示的正规方程组：<br>$X^T(Y-X\hat{\beta})=0\tag{2}$<br>移项得：<br>$X^TX\hat{\beta}=X^TY\tag{3}$<br>当$(X^TX)^{-1}$存在时，即得到模型参数的最小二乘估计为：<br>$\hat{\beta}=(X^TX)^{-1}X^TY\tag{4}$<br>依照（4）式求解$\hat{\beta_0}$,$\hat{\beta_1}$,$\hat{\beta_2}$,· · ·,$\hat{\beta_p}$的表达式称为参数$\beta_0$,$\beta_1$,$\beta_2$,· · ·,$\beta_p$的最小二乘估计。</p><p>代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#[B0,B1]=[4.50909240e+02,3.53898056e-01,-5.61475728e-01,-7.25399095e-03,2.15778604e+01,4.35188286e-01]</span></span><br><span class="line">Bhat=np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)</span><br><span class="line"></span><br><span class="line">Yhat=X.dot(Bhat)                                <span class="comment">#计算Y的估计值Yhat</span></span><br></pre></td></tr></table></figure><h5 id="2-求-hat-sigma-的估计，即模型标准误SE。"><a href="#2-求-hat-sigma-的估计，即模型标准误SE。" class="headerlink" title="2.求$\hat{\sigma}$的估计，即模型标准误SE。"></a>2.求$\hat{\sigma}$的估计，即模型标准误SE。</h5><p>&emsp;除了回归系数以外，多元线性回归模型中还包含了随机误差项的方差$/sigma^2$这个未知参数。与一元线性回归分析相似，多元线性回归模型中的 σ2 也是利用残差平方和除以其自由度来估计的，即有:<br>$\hat{\sigma}^2=\frac{SSE}{n-p-1}\tag{5}$</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">n=dat.shape[<span class="number">0</span>]                                  <span class="comment">#样本数</span></span><br><span class="line">p=x_dat.shape[<span class="number">1</span>]                                <span class="comment">#特征数</span></span><br><span class="line">SSE=(Y-Yhat).T.dot(Y-Yhat)</span><br><span class="line">MSE=SSE/(n-p<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型标准误sigmahat=49.492404133016464</span></span><br><span class="line">sigmahat=MSE**<span class="number">0.5</span></span><br></pre></td></tr></table></figure><h5 id="3-求SST，SSR和SSE，并计算判决系数-R-2-的值"><a href="#3-求SST，SSR和SSE，并计算判决系数-R-2-的值" class="headerlink" title="3.求SST，SSR和SSE，并计算判决系数$R^2$的值"></a>3.求SST，SSR和SSE，并计算判决系数$R^2$的值</h5><p>&emsp;样本复决定系数是回归平方和与总离差平方和之比，记为 R2 。该统计量可作为评价模型拟合优度的一项指标。利用总离差平方和的分解式:<br>$\sum_{i=1}^n(y_i-\overline y)^2=\sum_{i=1}^n(\hat{y_i}-\overline y)^2+\sum_{i=1}^n(y_i-\hat{y_i})^2\tag{6}$<br>上式可写为：总离差平方和 (SST)= 回归平方和 (SSR)+ 残差平方和 (SSE), 可得到样本复决定系数的计算公式为：<br>$R^2=\frac{SSR}{SST}=1-\frac{SSE}{SST}\tag{7}$</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#总离差平方和SST=13843371.75</span></span><br><span class="line">SST=(Y-Y.mean()).T.dot(Y-Y.mean())</span><br><span class="line"></span><br><span class="line"><span class="comment">#残差平方和SSE=24494.980668658252              </span></span><br><span class="line">SSE=(Y-Yhat).T.dot(Y-Yhat)</span><br><span class="line"></span><br><span class="line"><span class="comment">#回归平方和SSR=13818876.769331342</span></span><br><span class="line">SSR=SST-SSE</span><br><span class="line"></span><br><span class="line"><span class="comment">#判定系数Rsq=0.998230562531223</span></span><br><span class="line">Rsq=SSR/SST</span><br></pre></td></tr></table></figure><h5 id="4-求-hat-beta-1-的标准误-Se-hat-beta-1"><a href="#4-求-hat-beta-1-的标准误-Se-hat-beta-1" class="headerlink" title="4.求$\hat{\beta_1}$的标准误$Se(\hat{\beta_1})$"></a>4.求$\hat{\beta_1}$的标准误$Se(\hat{\beta_1})$</h5><p>&emsp;求$\hat{\beta_1}$的标准误公式为：<br>$Se(\hat{\beta_1})=\sqrt{c_{jj}}\hat{\sigma}\tag{8}$</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c_B1=np.diag(np.linalg.inv(X.T.dot(X)))[<span class="number">1</span>:<span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#标准误SE(B1)=[8.52296594e-02,1.25384291e-01,2.06677862e-03,4.03005054e+00,5.15596527e-02]</span></span><br><span class="line">se_B1hat=sigmahat*(c_B1**<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><h5 id="5-计算回归系数假设检验统计量-frac-hat-beta-1-Se-hat-beta-1-，并取0-05显著性水平，对回归系数-hat-beta-1-进行检验。"><a href="#5-计算回归系数假设检验统计量-frac-hat-beta-1-Se-hat-beta-1-，并取0-05显著性水平，对回归系数-hat-beta-1-进行检验。" class="headerlink" title="5.计算回归系数假设检验统计量$\frac{\hat{\beta_1}}{Se(\hat{\beta_1})}$，并取0.05显著性水平，对回归系数$\hat{\beta_1}$进行检验。"></a>5.计算回归系数假设检验统计量$\frac{\hat{\beta_1}}{Se(\hat{\beta_1})}$，并取0.05显著性水平，对回归系数$\hat{\beta_1}$进行检验。</h5><p>&emsp;当有了参数向量$\beta_j$的估计量$\hat{\beta_j}$时，$\hat{\beta_j}$与$\beta_j$的接近程度如何？这就需构造$\beta_j$的一个以$\hat{\beta_j}$为中心的区间，该区间以一定的概率包含$\beta_j$。由$\hat{\beta_j}\sim N(\beta_j, c_{jj}\sigma^2)(j=0,1,2,· · ·,p)$，可知:<br>$t_j=\frac{\hat{\beta_j}}{Se(\hat{\beta_j})}=\frac{\hat{\beta_j}-\beta}{\sqrt{c_{jj}}\hat{\sigma}}\sim t(n-p-1)\tag{9}$<br>$\beta_j$置信度为1-α的置信区间为：<br>$(\hat{\beta_j}-t_{\alpha/2}\sqrt{c_{jj}}\hat{\sigma},\hat{\beta_j}+t_{\alpha/2}\sqrt{c_{jj}}\hat{\sigma})$</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">B1hat=Bhat[<span class="number">1</span>:<span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#假设检验统计量t=[4.15228757,-4.47803886,-3.5098055,5.35424064,8.44048133]</span></span><br><span class="line">t_value=B1hat/se_B1hat</span><br><span class="line"></span><br><span class="line">rvt=stats.t(n-p<span class="number">-1</span>)                              <span class="comment">#创建自由度为n-p-1的t分布随机变量</span></span><br><span class="line">t_crit_value=rvt.ppf(<span class="number">0.975</span>)                     <span class="comment">#临界值t_crit_value=2.2281388519649385</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#p=[1.97281641e-03,1.18260509e-03,5.63348539e-03,3.21655887e-04,7.34117204e-06]  通过检验</span></span><br><span class="line">P_vt=(<span class="number">1</span>-rvt.cdf(np.abs(t_value)))*<span class="number">2</span></span><br></pre></td></tr></table></figure><h5 id="6-计算F统计量的值，并取0-05显著性水平，对整体线性显著性进行检验。"><a href="#6-计算F统计量的值，并取0-05显著性水平，对整体线性显著性进行检验。" class="headerlink" title="6.计算F统计量的值，并取0.05显著性水平，对整体线性显著性进行检验。"></a>6.计算F统计量的值，并取0.05显著性水平，对整体线性显著性进行检验。</h5><p>&emsp;当多元回归模型估计出来后，还需对整个模型的显著性进行检验。对多元线性回归方程显著性的F检验就是要检验自变量$x_1$,$x_2$,· · ·,$x_p$从整体上对随机变量y是否有明显的影响。其检验步骤为：<br>&emsp;第一步，提出假设。<br>$H_0:\beta_1=\beta_2=···=\beta_p=0,H_1:\exists\beta_j\in(\beta_1,\beta_2···\beta_p):  \beta_j\neq0\tag{10}$<br>&emsp;第二步，构建检验的F统计量，并计算F值。为了建立对H0进行检验的F统计量，仍然同一元线性回归分析一样，利用总离差平方和的分解式(6)，构造F统计量如下：<br>$F=\frac{SSR/p}{SSE/(N-P-1)}\tag{11}$<br>&emsp;在正态假设下，当原假设$H_0:\beta_1=\beta_2=···=\beta_p=0$成立时，服从自由度为(p,n−p−1)的F分布。于是，可以利用F统计量对回归方程的总体显著性进行检验。对于给定的n组数据$(x_{i1},x_{i2},···,x_{ip};yi)$(i=1, 2···,n)，计算出SSR和SSE，进而得到F的值，再由给定的显著性水平α,查F分布表，得到临界值$F \leq F_{\alpha}(p,n-p-1)$。<br>&emsp;第三步，作出统计决策。<br>&emsp;当$F&gt;F_{\alpha}(p,n-p-1)$时，拒绝原假设$H_0$，认为在显著性水平α下，$x_1$,$x_2$,···,$x_p$对y有显著的线性关系，也即认为回归方程是显著的；反之，当$F geq F_{\alpha}(p,n-p-1)$时，则认为回归方程不显著。<br>&emsp;也可以根据P值作检验。当P值≤α时，拒绝原假设$H_0$; 当P值≥α，不拒绝原假设$H_0$。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#F统计量的值F_v=1128.3027291393482</span></span><br><span class="line">F_v=MSR/MSE</span><br><span class="line"></span><br><span class="line">rvF=stats.f(p,n-p<span class="number">-1</span>)                            <span class="comment">#创建F分布</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#p=2.0305979120394113e-13 通过整体线性显著性检验</span></span><br><span class="line">P_vF=<span class="number">1</span>-rvF.cdf(F_v)</span><br></pre></td></tr></table></figure><h5 id="7-当X1-10000-X2-8000-X3-100000-X4-45-X5-3000-对y进行点预测，取置信水平95-，并对y进行平均值和个别值区间预测"><a href="#7-当X1-10000-X2-8000-X3-100000-X4-45-X5-3000-对y进行点预测，取置信水平95-，并对y进行平均值和个别值区间预测" class="headerlink" title="7.当X1=10000,X2=8000,X3=100000,X4=45,X5=3000,对y进行点预测，取置信水平95%，并对y进行平均值和个别值区间预测"></a>7.当X1=10000,X2=8000,X3=100000,X4=45,X5=3000,对y进行点预测，取置信水平95%，并对y进行平均值和个别值区间预测</h5><p>&emsp;在通过了各种检验后，多元线性回归模型便可用于预测。多元线性回归预测与一元线性回归预测的原理是一致的。当给定一组自变量的值$x_0=(x_{01},x_{02}···x_{0p})^T$，要估计所对应的$y_0$，很自然的想法就是将$x_0=(x_{01},x_{02}···x_{0p})^T$的值代入到回归方程中去，直接算出点估计值$\hat{y_0}$：<br>$\hat{y_0}=\hat{\beta_0}+\hat{\beta_1}x_{01}+···+\hat{\beta_p}x_{0p}\tag{12}$<br>&emsp;给定1−α的置信水平下$Y_0$的置信区间为：<br>$[\hat{y_0}-t_{\alpha/2}\times\hat{\sigma}\sqrt{1+x_0(X_TX)^{-1}X_0^T},\hat{y_0}+t_{\alpha/2}\times\hat{\sigma}\sqrt{1+x_0(X_TX)^{-1}X_0^T}]\tag{13}$<br>1−α的置信度下E(y0)的置信区间为:<br>$[\hat{y_0}-t_{\alpha/2}\times\hat{\sigma}\sqrt{x_0(X_TX)^{-1}X_0^T},\hat{y_0}+t_{\alpha/2}\times\hat{\sigma}\sqrt{x_0(X_TX)^{-1}X_0^T}]\tag{14}$</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x_new_dat=pd.DataFrame(&#123;<span class="string">'x1'</span>:<span class="number">10000</span>,<span class="string">'x2'</span>:<span class="number">8000</span>,<span class="string">'x3'</span>:<span class="number">100000</span>,<span class="string">'x4'</span>:<span class="number">45</span>,<span class="string">'x5'</span>:<span class="number">3000</span>&#125;,index=[<span class="number">0</span>])</span><br><span class="line">x_ones=pd.DataFrame(np.repeat(<span class="number">1</span>,x_new_dat.shape[<span class="number">0</span>])) </span><br><span class="line">x_new=pd.concat([x_ones,x_new_dat],axis=<span class="number">1</span>).values.flatten()</span><br><span class="line"></span><br><span class="line"><span class="comment">#点预测y_pre=1049.25344924</span></span><br><span class="line">y_pre=x_new.dot(Bhat)</span><br><span class="line"></span><br><span class="line"><span class="comment">#个别值预测区间[1041.23496487, 1057.27193362]</span></span><br><span class="line">y_ind=np.array([x_new.dot(Bhat)-t_crit_value*(<span class="number">1</span>+x_new.dot(np.linalg.inv(X.T.dot(X))).dot(x_new.T))**<span class="number">0.5</span>,x_new.dot(Bhat)+t_crit_value*(<span class="number">1</span>+x_new.dot(np.linalg.inv(X.T.dot(X))).dot(x_new.T))**<span class="number">0.5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#平均值预测区间[1041.55075563, 1056.95614286]</span></span><br><span class="line">y_avg=np.array([x_new.dot(Bhat)-t_crit_value*(x_new.dot(np.linalg.inv(X.T.dot(X))).dot(x_new.T))**<span class="number">0.5</span>,x_new.dot(Bhat)+t_crit_value*(x_new.dot(np.linalg.inv(X.T.dot(X))).dot(x_new.T))**<span class="number">0.5</span>])</span><br></pre></td></tr></table></figure><h5 id="使用statsmodels模块对上述结果进行检验"><a href="#使用statsmodels模块对上述结果进行检验" class="headerlink" title="使用statsmodels模块对上述结果进行检验"></a>使用statsmodels模块对上述结果进行检验</h5><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br><span class="line"></span><br><span class="line">lm1=sm.OLS(Y,X).fit()</span><br><span class="line">type(lm1)</span><br><span class="line">lm1.summary()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;根据所给样本数据，建立线性回归模型-Y-i-beta-0-beta-1X-i-mu-i-，其中-mu-i-sim-N-0-sigma-2&quot;&gt;&lt;a href=&quot;#根据所给样本数据，建立线性回归模型-Y-i-beta-0-beta-1X-i-mu-i-，其中-mu-i-sim-N-0-sigma-2&quot; class=&quot;headerlink&quot; title=&quot;根据所给样本数据，建立线性回归模型$Y_i=\beta_0+\beta_1X_i+\mu_i$，其中${\mu}_i \sim N(0,\sigma^2)$&quot;&gt;&lt;/a&gt;根据所给样本数据，建立线性回归模型$Y_i=\beta_0+\beta_1X_i+\mu_i$，其中${\mu}_i \sim N(0,\sigma^2)$&lt;/h4&gt;&lt;p&gt;&amp;emsp;多元线性回归模型是指描述因变量y与一组自变量$x_1$,$x_1$,· · · ,$x_p$以及随机误差项ε的关系的等式。其一般表达式为：&lt;br&gt;$y=\beta_0+\beta_1x_1+\beta_2x_2+···+\beta_px_p+\varepsilon\tag{1}$&lt;br&gt;式中，$\beta_0$,$\beta_1$,$\beta_2$,· · ·,$\beta_p$是p+1个未知参数，$\beta_0$称为回归截距，$\beta_1$,· · ·,$\beta_p$称为回归系数，ε是随机误差项。y称为被解释变量（因变量），而$x_1$,$x_1$,· · ·,$x_p$是p个可以精确测量并可控制的自变量，称为解释变量。p=1时，式(1)即为一元线性回归模型，p≥2时，则称式(1)为多元线性回归模型。&lt;/p&gt;
&lt;p&gt;数据导入代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; scipy &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; stats&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;dat=pd.read_excel(&lt;span class=&quot;string&quot;&gt;&#39;dat.xls&#39;&lt;/span&gt;)                    &lt;span class=&quot;comment&quot;&gt;#读取数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ones=pd.DataFrame(np.repeat(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,dat.shape[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;]))    &lt;span class=&quot;comment&quot;&gt;#创建维度为dat.shape[0]的全为1的数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;x_dat=dat.iloc[:,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;]                           &lt;span class=&quot;comment&quot;&gt;#取源数据的第3列至第7列做为特征值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;X=pd.concat([ones,x_dat],axis=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)                &lt;span class=&quot;comment&quot;&gt;#合并1和特征值作为输入X &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Y=dat.y                                         &lt;span class=&quot;comment&quot;&gt;#取源数据y值作为输出Y&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="广义线性模型" scheme="https://ccchff.github.io/categories/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="GLM" scheme="https://ccchff.github.io/tags/GLM/"/>
    
      <category term="python" scheme="https://ccchff.github.io/tags/python/"/>
    
  </entry>
  
</feed>
